{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuniorHZ19/HerramientasIA/blob/main/imagetoimageWaveGenerator7.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bing_image_downloader"
      ],
      "metadata": {
        "id": "YdxLa99DFYhQ",
        "outputId": "360e7b2d-5612-448b-c800-c23610b7a94f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bing_image_downloader in /usr/local/lib/python3.10/dist-packages (1.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bing_image_downloader import downloader\n",
        "\n",
        "\n",
        "downloader.download(\"animes\", limit=100,  output_dir='dataset',\n",
        "                    adult_filter_off=True, force_replace=False, timeout=60)"
      ],
      "metadata": {
        "id": "xGmOSzG1Kt6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
        "!unzip DIV2K_train_HR.zip # This is our dataset link. I will include this command in the description"
      ],
      "metadata": {
        "id": "hsgw-_4AS6fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *0) ** Instalando libreria(OBLIGATORIO)\n",
        "\n",
        "!pip install torch torchvision torchaudio\n"
      ],
      "metadata": {
        "id": "R0Je-JZAxuYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dosBBs15UdPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nXtHMrXAUc3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.rmtree(\"/content/imagenes\")"
      ],
      "metadata": {
        "id": "jMdsEbI7OPEO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *1) ** Clase Para manejo de directorios de datasets de imagenes\n",
        "\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "# Recorre el directorio  y elmiina los archvios que no tiene las extensioens permitidas\n",
        "\n",
        "class DataSetManage:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " def comprobar_ext_directorios(self,directorio):\n",
        "\n",
        "  for clase,[directorio,etiquetas] in(directorio.items()):\n",
        "   lista_directorio=os.listdir(directorio)\n",
        "   self._validarExt(directorio)\n",
        "\n",
        "\n",
        "\n",
        " def  _validarExt(self,directorio):\n",
        "  print(directorio)\n",
        "   # Extensiones permitidas\n",
        "  extensiones_permitidas = {\".jpg\", \".jpeg\", \".png\"}\n",
        "  for root, dirs, files in os.walk(directorio):\n",
        "\n",
        "    for file in files:\n",
        "        # Obtiene la extensión del archivo\n",
        "        _, extension = os.path.splitext(file)\n",
        "\n",
        "        # Verifica si la extensión no está en la lista de extensiones permitidas y elimina el archivo\n",
        "        if extension.lower() not in extensiones_permitidas:\n",
        "            archivo_a_eliminar = os.path.join(root, file)\n",
        "            os.remove(archivo_a_eliminar)\n",
        "            print(f\"Se eliminó: {archivo_a_eliminar}\")\n",
        "\n",
        "\n",
        "# Cambia nombre de cada archivo dentro del directorio a un valor secuencial\n",
        "\n",
        " def cambiar_nombres_directorios(self,directorio):\n",
        "   for clase,[directorio,etiquetas] in(directorio.items()):\n",
        "     lista_directorio=os.listdir(directorio)\n",
        "     self._cambiarNombre(directorio,clase)\n",
        "     print(directorio)\n",
        "\n",
        "\n",
        " def _cambiarNombre(self,directorios,subfijo):\n",
        "  archivos_en_directorio = os.listdir(directorios)\n",
        "  for i, archivo in enumerate(archivos_en_directorio, start=1):\n",
        "    # Construir el nuevo nombre del archivo\n",
        "    nuevo_nombre = f\"{subfijo}{i}{os.path.splitext(archivo)[1]}\"\n",
        "\n",
        "    # Ruta completa del archivo antiguo y nuevo\n",
        "    ruta_antigua = os.path.join(directorios, archivo)\n",
        "    ruta_nueva = os.path.join(directorios, nuevo_nombre)\n",
        "\n",
        "    # Cambiar el nombre del archivo\n",
        "    os.rename(ruta_antigua, ruta_nueva)\n",
        "    print(f\"Se cambió el nombre de {ruta_antigua} a {ruta_nueva}\")\n",
        "\n",
        "\n",
        "#Obtiene la cantidad de elemntos que tiene la carpeta\n",
        "\n",
        " def len_directorio(self,directorio):\n",
        "    cantidad_elementos = sum(1 for elemento in os.listdir(directorio) if os.path.isfile(os.path.join(directorio, elemento)))\n",
        "    return cantidad_elementos\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------------------------------\n",
        "\n",
        "#Valida si la imagen se puede leer usando  pill o cv2 si no se puede leer se elimina\n",
        "\n",
        " def validar_Img_Pill(self,directorio,):\n",
        "  for etiqueta,[directorio,clase] in(directorio.items()):\n",
        "\n",
        "    lista_paths=os.listdir(directorio)\n",
        "    self._validarLecturaImgPill(directorio,lista_paths)\n",
        "  print(f\"Se ah validado todas las imagenes\")\n",
        "\n",
        " def validar_Img_cv2(self,directorio):\n",
        "  for etiqueta,[directorio,clase] in(directorio.items()):\n",
        "\n",
        "    lista_paths=os.listdir(directorio)\n",
        "    self._validarLecturaImg(directorio,lista_paths)\n",
        "  print(f\"Se ah validado todas las imagenes\")\n",
        "\n",
        " def _validarLecturaImg(self,directorio,lista):\n",
        "\n",
        "  for ruta in(lista):\n",
        "   imagen=cv2.imread(directorio+ruta)\n",
        "   if  imagen is None:\n",
        "     os.remove(directorio+ruta)\n",
        "     print(f\"No se pudo leer y se elimino archivo:{directorio+ruta}\")\n",
        "\n",
        " def _validarLecturaImgPill(self,directorio,lista):\n",
        "    for ruta in(lista):\n",
        "     try:\n",
        "      imagen=Image.open(directorio+ruta)\n",
        "     except Exception as e:\n",
        "      os.remove(directorio+ruta)\n",
        "      print(f\"Archivo '{directorio+ruta}' eliminado.\")\n",
        "\n",
        "\n",
        "\n",
        "#vamos a recorrer el dicionario y validar ruta por ruta si se puede leer sino se elminara\n",
        "#vamos guaradno al mismo tiempo 3 listas, los directorios , listas de paths de los directiros y de las clases ,para usarlo luego usarlo al crear el csv\n",
        "\n",
        " def separar_datos_directorios(self,directorios):\n",
        "  listas_directorios=[]\n",
        "  listas_listas_directorios=[]\n",
        "  listas_clases=[]\n",
        "\n",
        "  for etiqueta,[directorio,clase] in(directorios.items()):\n",
        "\n",
        "       lista_paths=os.listdir(directorio)\n",
        "       listas_directorios.append(directorio)\n",
        "       listas_listas_directorios.append(lista_paths)\n",
        "       listas_clases.append(clase)\n",
        "\n",
        "  return listas_directorios,listas_listas_directorios,listas_clases\n",
        "\n",
        " def emparejar_listas_paths(self,lista_listas):\n",
        "\n",
        "   #Tomamos el minimo tamaño dentro de las lista de cada clase\n",
        "   tamaño_minimo = min(len(arr) for arr in lista_listas)\n",
        "\n",
        "   #Vamos a emparejar todas las listas con un tamaño igual que sea la del minimo tamaño de todas,esto para tener un set de datos parejo por cada clase\n",
        "   Reducido_lista_paths=[]\n",
        "\n",
        "   #Reduce cada lista de los paths a la cantidad minimo para que todos tenga iaugal cantidad\n",
        "   for listas in(lista_listas):\n",
        "    Reducido_lista_paths.append(listas[:tamaño_minimo])\n",
        "\n",
        "   return Reducido_lista_paths\n",
        "#---------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        " def crear_paths_csv(self,directorio_base,lista_paths,clases,nombre_archivo):\n",
        "\n",
        "   columnas=[\"path\",\"etiqueta\"]\n",
        "   datos_csv=[]\n",
        "\n",
        "   for dir_base,dir_path,clase in  zip(directorio_base,lista_paths,clases):\n",
        "\n",
        "    for path  in (dir_path):\n",
        "\n",
        "     datos_csv.append([dir_base+path ,clase])\n",
        "\n",
        "\n",
        "   df_lista=pd.DataFrame(datos_csv,columns=columnas)\n",
        "   df_lista=df_lista.sort_values(by='path')\n",
        "   df_lista.to_csv(nombre_archivo,index=False)\n",
        "   print(\"Csv Creado\")\n",
        "#---------------------------------------------------------------------------------\n",
        "\n",
        "#devuelve cuatnos elemtnos tiene cada clase\n",
        " def total_elementos(self,directorio,csv_path):\n",
        "    df=pd.read_csv(csv_path)\n",
        "    for clase,[directorio,etiqueta] in (directorio.items()):\n",
        "     tamaño_etiqueta=(df[\"etiqueta\"] == etiqueta).sum()\n",
        "     print(f\"la clase {clase} tiene :{tamaño_etiqueta} elementos\")\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------------------------\n",
        "\n",
        "  #Funciones para data aumentation\n",
        " def   data_aumentation_conjunto(self,input_imagen_folder,output_path_folder,iteraciones,transformaciones,keepname=False):  #ingresa trnasformacioens como compose donde se aplicara las trasnfomracioens conjutnos pero se repteira un numero de veces por cada imagen\n",
        "\n",
        "   for filename in os.listdir(input_imagen_folder):\n",
        "\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "\n",
        "        input_path = os.path.join(input_imagen_folder, filename)\n",
        "        if(keepname==False):\n",
        "         output_path = os.path.join(output_path_folder, f'transformed_{filename}')\n",
        "        else:\n",
        "          output_path = os.path.join(output_path_folder, f'{filename}')\n",
        "        # Aplica las transformaciones\n",
        "        print(output_path)\n",
        "        self._apply_transfomaciones_conjunto_it(input_path,output_path,int(iteraciones),transformaciones,keepname)\n",
        "\n",
        "\n",
        " def   data_aumentation_individual(self,input_imagen_folder,output_path_folder,transformaciones,keepname=False):  #las trnasfomaciones solo pasaremos la lista ya que ira aplicando la transformacion una por una por cada imagen\n",
        "\n",
        "  for filename in os.listdir(input_imagen_folder):\n",
        "\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "        input_path = os.path.join(input_imagen_folder, filename)\n",
        "        if(keepname==False):\n",
        "         output_path = os.path.join(output_path_folder, f'transformed_{filename}')\n",
        "         print(\"opasasmos\")\n",
        "        else:\n",
        "          output_path = os.path.join(output_path_folder, f'{filename}')\n",
        "        # Aplica las transformaciones\n",
        "        self._apply_transfomaciones_conjunto(input_path,output_path,transformaciones,keepname)\n",
        "\n",
        "\n",
        "\n",
        " def _apply_transfomaciones_conjunto_it(self,input_imagen_path,output_iamgen_path,iteraciones,transformations=None,keepname=False): #aplica las transfomracioens  conjutas por iteracion y se guarda las iamgenes\n",
        "\n",
        "   imagen=Image.open(input_imagen_path).convert(\"RGB\")\n",
        "\n",
        "\n",
        "   for i in range(iteraciones):\n",
        "      imagen_trasformada=transformations(imagen)\n",
        "\n",
        "      out_root, out_extension = os.path.splitext(output_iamgen_path)\n",
        "      if(keepname==False):\n",
        "       imagen_trasformada.save(f\"{out_root}_{i}{out_extension}\")\n",
        "      else:\n",
        "        imagen_trasformada.save(f\"{out_root}{out_extension}\")\n",
        "\n",
        " def _apply_transfomaciones_conjunto(self,input_imagen_path,output_iamgen_path,transformations=None,keepname=False): #aplica las transfomracioens individuales  y se guarda las iamgenes\n",
        "\n",
        "  imagen=Image.open(input_imagen_path).convert(\"RGB\")\n",
        "\n",
        "  for i,transformacion in enumerate(transformations):\n",
        "   imagen_transformada=transformacion(imagen)\n",
        "   out_root, out_extension = os.path.splitext(output_iamgen_path)\n",
        "   if(keepname==False):\n",
        "     imagen_transformada.save(f\"{out_root}_{i}{out_extension}\")\n",
        "   else:\n",
        "      imagen_transformada.save(f\"{out_root}{out_extension}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4Byd3D3TT7Ov",
        "cellView": "form"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Creamos las carpetas con las imagenes en hr y lw\n",
        "\n",
        "#Creamos los arhcivo baja resolucion aparitr de imangenes alta resoulcion en hr , estos archios iran a carpaeta lw\n",
        "directorio_in=\"/content/dataset/animes\"\n",
        "directorio_out=\"/content/imagenes/\"\n",
        "\n",
        "#antes de otrogar mediads de hr y lw , chekea como el generador va votando las resolucioens hr_fake segun la resolucion lw que especifics tiene qeu conicidr\n",
        "#ya que el discriminador necsita la misma medidades tanto para el hr y el hr_fake que genera el generador\n",
        "\n",
        "transformaciones=transforms.Compose([\n",
        "transforms.Resize((256,256)),\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "datasetmanage=DataSetManage()\n",
        "datasetmanage.data_aumentation_conjunto(directorio_in,directorio_out,1,transformaciones)\n"
      ],
      "metadata": {
        "id": "IGhbwh-jOnFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dmg=DataSetManage()\n",
        "directoriolw={\n",
        "     \"img\":[\"/content/imagenes/\",1],\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "listas_directorios,listas_paths_directorios,listas_clases=dmg.separar_datos_directorios(directoriolw)\n",
        "Dataset_csv=\"dataset.csv\" #nombre que tenda nuestlo csv\n",
        "dmg.crear_paths_csv(listas_directorios,listas_paths_directorios,listas_clases,Dataset_csv)\n",
        "\n"
      ],
      "metadata": {
        "id": "Kzybet7nU6gH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1282d8-55e4-4e94-d689-ad1a39e610a2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Csv Creado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DEFNIIR DISPOSITIVO:\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"CUDA está disponible.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"CUDA no está disponible. Se utilizará la CPU.\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "Q1hgFUL5RRgz",
        "outputId": "b953041b-e285-4f0c-a08e-831ff363bb66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA está disponible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *2) ** Creacion de clase DATASET(OBLIGATORIO)\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n",
        "class MiDataSet(Dataset):\n",
        "    def __init__(self, csv, transform=None):\n",
        "        self.data = pd.read_csv(csv)\n",
        "        self.path = self.data[\"path\"]\n",
        "        self.samples = self.data[\"path\"].shape[0]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ruta = self.path[idx]\n",
        "\n",
        "        # Abrir la imagen\n",
        "        img = Image.open(ruta).convert(\"RGB\")\n",
        "\n",
        "        l_channel,ab_channel =self.rgb_a_lab(img)\n",
        "\n",
        "        #normalizar:\n",
        "        ab_channel_normalizado=(((ab_channel+ 128) / 255) * 2) - 1  #normalizado ab que va de -128 a 127  a un rango -1 a 1 para que conicida con la salida de generador\n",
        "        l_channel_normalizado=l_channel/100 #normalizado l que va de 0-100 a un  rango 0-1\n",
        "\n",
        "        if self.transform:\n",
        "            l_tensor= self.transform(l_channel_normalizado)\n",
        "            ab_tensor = self.transform(ab_channel_normalizado)\n",
        "\n",
        "        return l_tensor, ab_tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.samples\n",
        "\n",
        "    def rgb_a_lab(self,img):\n",
        "\n",
        "      lab_image=rgb2lab(img)\n",
        "\n",
        "      # Separa los canales L y AB\n",
        "      l_channel = lab_image[:,:, 0]\n",
        "      ab_channel=lab_image[:,:, 1:]\n",
        "\n",
        "\n",
        "      return l_channel,ab_channel\n",
        "\n",
        "    def lab_a_rgb(self,l,ab):\n",
        "      rgb_image=np.zeros((256,256,3))\n",
        "      rgb_image[:,:,0]=l\n",
        "      rgb_image[:,:,1:]=ab\n",
        "      return lab2rgb(rgb_image)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5vcmR_ZKhkGs",
        "cellView": "form"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " from PIL import Image\n",
        " img = Image.open(\"/content/imagenes/transformed_Image_3_0.jpg\")\n",
        " array_img=np.array(img)\n",
        "\n",
        " lab_image=rgb2lab(img)\n",
        " l=lab_image[:,:,0]\n",
        " ab=lab_image[:,:,1:]\n",
        "\n",
        "\n",
        " print(np.max(ab))\n"
      ],
      "metadata": {
        "id": "z8DBb7MIxn-O",
        "outputId": "395011d3-a391-47f1-bf96-d4d9a6f04426",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62.35266326525624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CREANDO DATASETS Y DATALOADERS:\n",
        "from skimage.color import lab2rgb\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "transformaciones = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "])\n",
        "\n",
        "batch_size=10\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dataset =MiDataSet(\"/content/dataset.csv\",transformaciones)\n",
        "data_loader=DataLoader(dataset,batch_size=batch_size)\n",
        "\n",
        "l1,ab=dataset.__getitem__(2)\n",
        "\n",
        "ab_desnormalizado=((((ab+1)/2)*255))-128\n",
        "\n",
        "l1_desnormalizado=l1*100\n",
        "\n",
        "#Estructura imagen sera la variable que usaremos como base donde se pondra cada canal l ab\n",
        "\n",
        "estructura_imagen=np.zeros((512, 512, 3))\n",
        "\n",
        "#Visualisando\n",
        "\n",
        "l1 = l1_desnormalizado.squeeze().numpy()\n",
        "ab = ab_desnormalizado.squeeze().permute(1, 2, 0).numpy()\n",
        "\n",
        "# Visualizar la imagen generada\n",
        "# Subfigura l1\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(l1,cmap='gray')\n",
        "plt.title('l1')\n",
        "\n",
        "# Subfigura ab\n",
        "plt.subplot(1, 3, 2)\n",
        "\n",
        "img_ab = estructura_imagen # crea un array de ceros para la imagen RGB\n",
        "img_ab[:,:,1:] = ab\n",
        "plt.imshow(img_ab)\n",
        "plt.title('ab')\n",
        "\n",
        "\n",
        "# Subfigura rgb\n",
        "plt.subplot(1, 3, 3)\n",
        "\n",
        "img_rgb = estructura_imagen  # crea un array de ceros para la imagen RGB\n",
        "img_rgb[:,:,0]=l1\n",
        "img_rgb[:,:,1:] = ab\n",
        "\n",
        "plt.imshow(lab2rgb(img_rgb))\n",
        "plt.title('rgb')\n",
        "\n",
        "# Ajustar diseño\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar las imágenes\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nrIpUc77941u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0u08uaQuAjjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1WYVki2qv_EJ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # *0) ** Creando clase Discriminadora:\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class cnnBlock(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels,stride=2):\n",
        "   super(cnnBlock,self).__init__()\n",
        "   self.conv=nn.Sequential(\n",
        "         nn.Conv2d(in_channels,out_channels,4,stride,padding=1),\n",
        "         nn.BatchNorm2d(out_channels),\n",
        "         nn.LeakyReLU(0.2),\n",
        "     )\n",
        "  def forward(self,x):\n",
        "    return self.conv(x)\n",
        "\n",
        "class Discriminator (nn.Module):\n",
        "  def __init__(self):\n",
        "   super(Discriminator,self).__init__()\n",
        "\n",
        "   self.inicial=nn.Sequential(\n",
        "                           nn.Conv2d(3,64,4,2,1),\n",
        "                           nn.LeakyReLU(0.2),\n",
        "                        )\n",
        "\n",
        "   self.cnnblock1=cnnBlock(64,128)\n",
        "   self.cnnblock2=cnnBlock(128,256)\n",
        "   self.cnnblock3=cnnBlock(256,512,stride=1)\n",
        "\n",
        "   self.lastconv= nn.Conv2d(512,1,4,1,1)\n",
        "\n",
        "\n",
        "  def forward(self,x,y):\n",
        "\n",
        "    x=torch.cat([x,y],dim=1)\n",
        "\n",
        "    x=self.inicial(x)\n",
        "    x=self.cnnblock1(x)\n",
        "    x=self.cnnblock2(x)\n",
        "    x=self.cnnblock3(x)\n",
        "\n",
        "    x=self.lastconv(x)\n",
        "    out=torch.sigmoid(x)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d=Discriminator()\n",
        "x = torch.randn(2, 1, 256, 256)  # Ejemplo de tensor x con 3 canales\n",
        "y = torch.randn(2, 2, 256, 256)  # Ejemplo de tensor y con 5 canales\n",
        "\n",
        "# Concatenar los tensores x e y a lo largo de la dimensión de los canales\n",
        "ju=d(x,y)\n",
        "print(ju.shape)"
      ],
      "metadata": {
        "id": "yvt4-WkNwMDr",
        "outputId": "d87f3e78-0500-4184-aa79-3e5f152c14e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1, 30, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminador=Discriminator()\n",
        "discriminador=discriminador.to(device)\n",
        "x=torch.randn(20,3,256,256).to(device)\n",
        "y=torch.randn(20,3,256,256).to(device)\n",
        "print(discriminador(x,y).shape)"
      ],
      "metadata": {
        "id": "UJ1Z0_7emJxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "126a91e3-5b84-4a85-82e2-49124c8cd786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 1, 30, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *2) ** GENERADOR U NET SIN SKIPS 256 X256 ENTRA L CANAL SALE 2 CANALES AB(OBLIGATORIO)\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "#---------------------GENERADOR BASADO EN U- NET---------------------------------------------------\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#input debe ser 256x256 otras dimeneoins  puede que tenega eror al mometno de concat las dimenes reducidas debe de conicidir y este unetblacok se ajsuta a una etnrada 256x256\n",
        "class U_Net_block(nn.Module):\n",
        "\n",
        "  def __init__(self,in_channel,out_channel,type,activacion=\"leakyrelu\",dropout_on=\"False\"):\n",
        "   super(U_Net_block,self).__init__()\n",
        "\n",
        "   if type==\"down\" :\n",
        "\n",
        "    self.block=nn.Conv2d(in_channel,out_channel,kernel_size=4,stride=2,padding=1,bias=False)\n",
        "\n",
        "   elif type==\"up\":\n",
        "\n",
        "    self.block=nn.Conv2d(in_channel,out_channel,kernel_size=3,stride=1,padding=1,bias=False)\n",
        "\n",
        "   self.batchnorm=nn.BatchNorm2d(out_channel)\n",
        "\n",
        "   self.activacion=activacion\n",
        "   self.leakyrelu=nn.LeakyReLU(0.2)\n",
        "   self.relu=nn.ReLU()\n",
        "\n",
        "   self.dropout_on=dropout_on # solo si necsitmos usar el dropout\n",
        "\n",
        "   self.dropout=nn.Dropout(0.5)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "     x=self.block(x)\n",
        "     x=self.batchnorm(x)\n",
        "\n",
        "     if(self.activacion==\"leakyrelu\"):\n",
        "      out=self.leakyrelu(x)\n",
        "     else:\n",
        "      out=self.relu(x)\n",
        "\n",
        "     if(self.dropout_on==True):\n",
        "      out=self.dropout(x)\n",
        "\n",
        "     return out\n",
        "\n",
        "\n",
        "class Generator_U_Net(nn.Module):\n",
        "\n",
        "    def __init__(self,in_channel=3):\n",
        "        super(Generator_U_Net,self).__init__()\n",
        "\n",
        "        # Encoder Seccion:\n",
        "\n",
        "        self.inicial=nn.Sequential(\n",
        "            nn.Conv2d(in_channel,64,kernel_size=4,stride=2,padding=1,bias=False), # primer bloque convolucional down no tiene batchnorm\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "\n",
        "        self.encoder1=U_Net_block(64,128,\"down\",activacion=\"leakyrelu\")\n",
        "        self.encoder2=U_Net_block(128,256,\"down\",activacion=\"leakyrelu\")\n",
        "        self.encoder3=U_Net_block(256,512,\"down\",activacion=\"leakyrelu\")\n",
        "        self.encoder4=U_Net_block(512,512,\"down\",activacion=\"leakyrelu\")\n",
        "        self.encoder5=U_Net_block(512,512,\"down\",activacion=\"leakyrelu\")\n",
        "        self.encoder6=U_Net_block(512,512,\"down\",activacion=\"leakyrelu\")\n",
        "        self.encoder7=U_Net_block(512,512,\"down\",activacion=\"leakyrelu\")\n",
        "\n",
        "\n",
        "        # Decoder Seccion:\n",
        "\n",
        "\n",
        "        self.decoder1=U_Net_block(512,512,\"up\",activacion=\"relu\")\n",
        "        self.decoder2=U_Net_block(512,512,\"up\",activacion=\"relu\")\n",
        "        self.decoder3=U_Net_block(512,512,\"up\",activacion=\"relu\")\n",
        "        self.decoder4=U_Net_block(512,256,\"up\",activacion=\"relu\")\n",
        "        self.decoder5=U_Net_block(256,128,\"up\",activacion=\"relu\")\n",
        "        self.decoder6=U_Net_block(128,64,\"up\",activacion=\"relu\")\n",
        "        self.decoder7=U_Net_block(64,64,\"up\",activacion=\"relu\")\n",
        "\n",
        "        # Last\n",
        "        self.convlast=nn.Conv2d(64,256,kernel_size=3,stride=1,padding=1,bias=False)\n",
        "        self.extra=nn.Conv2d(256,2,kernel_size=3,stride=1,padding=1,bias=False)\n",
        "\n",
        "        self.than=nn.Tanh()\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        d1=self.inicial(x) # d1 ->64 out\n",
        "        d2=self.encoder1(d1) # d2 ->128 out\n",
        "        d3=self.encoder2(d2) # d3 ->256 out\n",
        "        d4=self.encoder3(d3) # d4 ->512 out\n",
        "        d5=self.encoder4(d4) # d5 ->512 out\n",
        "        d6=self.encoder5(d5) # d6 ->512 out\n",
        "        d7=self.encoder6(d6) # d7 ->512 out\n",
        "        d8=self.encoder6(d7) # d7 ->512 out\n",
        "\n",
        "\n",
        "        e1=self.decoder1(d8) #e1 -> 512 out\n",
        "        e1=F.interpolate(e1,scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        e2=self.decoder2(e1) # e2  in ->512+512=1024  out->512\n",
        "        e2=F.interpolate(e2,scale_factor=2, mode='bilinear', align_corners=False)\n",
        "\n",
        "        e3=self.decoder3(e2) # e3  in ->512+512=1024   out->512\n",
        "        e3=F.interpolate(e3,scale_factor=2, mode='bilinear', align_corners=False)\n",
        "\n",
        "        e4=self.decoder4(e3) # e4 in ->512+512=1024   out->512\n",
        "        e4=F.interpolate(e4,scale_factor=2, mode='bilinear', align_corners=False)\n",
        "\n",
        "        e5=self.decoder5(e4)# e5 in ->512+512=1024    out->256\n",
        "        e5=F.interpolate(e5,scale_factor=2, mode='bilinear', align_corners=False)\n",
        "\n",
        "        e6=self.decoder6(e5) # e6 in ->256+256=512   out->128\n",
        "        e6=F.interpolate(e6,scale_factor=2, mode='bilinear', align_corners=False)\n",
        "\n",
        "        e7=self.decoder7(e6)\n",
        "        e7=F.interpolate(e7,scale_factor=2, mode='bilinear', align_corners=False)\n",
        "\n",
        "        out=self.convlast(e7) # last in 64+64  out->3\n",
        "        out=F.interpolate(out,scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        out=self.extra(out)\n",
        "        out=self.than(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "IK2VaCC30x6w",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "J3iLk4QM77zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *2) ** GENERADOR 256 X256 ENTRA L CANAL SALE 2 CANALES AB(OBLIGATORIO)\n",
        "\n",
        "#---------------------GENERADOR BASADO EN U- NET---------------------------------------------------\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "#input debe ser 80x80 otras dimeneoins  puede que tenega eror al mometno de concat las dimenes reducidas debe de conicidir y este unetblacok se ajsuta a una etnrada 256x256\n",
        "class U_Net_block(nn.Module):\n",
        "\n",
        "  def __init__(self,in_channel,out_channel,type,btchnm=True,activacion=\"leakyrelu\",dropout_on=\"False\"):\n",
        "   super(U_Net_block,self).__init__()\n",
        "\n",
        "   self.type=type\n",
        "   self.blockdown=nn.Conv2d(in_channel,out_channel,kernel_size=4,stride=2,padding=1,bias=False)\n",
        "   self.blockup=nn.Conv2d(in_channel,out_channel,kernel_size=3,stride=1,padding=1,bias=False)\n",
        "   self.batchnorm=nn.BatchNorm2d(out_channel)\n",
        "\n",
        "   self.activacion=activacion\n",
        "   self.leakyrelu=nn.LeakyReLU(0.2)\n",
        "   self.relu=nn.ReLU()\n",
        "   self.btchnm_on=btchnm\n",
        "   self.btchnorm=nn.BatchNorm2d(out_channel)\n",
        "   self.dropout_on=dropout_on # solo si necsitmos usar el dropout\n",
        "\n",
        "   self.dropout=nn.Dropout(0.5)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    if self.type==\"down\" :\n",
        "     x=self.blockdown(x)\n",
        "\n",
        "    elif self.type==\"up\":\n",
        "     x=self.blockup(x)\n",
        "     x=F.interpolate(x,scale_factor=2, mode='bilinear', align_corners=False)\n",
        "\n",
        "\n",
        "    if self.btchnm_on==True:\n",
        "     x=self.btchnorm(x)\n",
        "\n",
        "    if(self.activacion==\"leakyrelu\"):\n",
        "      out=self.leakyrelu(x)\n",
        "    else:\n",
        "      out=self.relu(x)\n",
        "\n",
        "    if(self.dropout_on==True):\n",
        "      out=self.dropout(x)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "class Generator_U_Net(nn.Module):\n",
        "\n",
        "    def __init__(self,in_channel=3):\n",
        "        super(Generator_U_Net,self).__init__()\n",
        "\n",
        "        # Encoder Seccion:\n",
        "\n",
        "        self.inicial=U_Net_block(1,64,\"down\",btchnm=False,activacion=\"leakyrelu\")\n",
        "\n",
        "\n",
        "        self.encoder1=U_Net_block(64,128,\"down\",btchnm=True,activacion=\"leakyrelu\")\n",
        "        self.encoder2=U_Net_block(128,256,\"down\",btchnm=True,activacion=\"leakyrelu\")\n",
        "        self.encoder3=U_Net_block(256,512,\"down\",btchnm=True,activacion=\"leakyrelu\")\n",
        "        self.encoder4=U_Net_block(512,512,\"down\",btchnm=True,activacion=\"leakyrelu\")\n",
        "        self.encoder5=U_Net_block(512,512,\"down\",btchnm=True,activacion=\"leakyrelu\")\n",
        "        self.encoder6=U_Net_block(512,512,\"down\",btchnm=True,activacion=\"leakyrelu\")\n",
        "\n",
        "        self.bottleneck=U_Net_block(512,512,\"down\",btchnm=False,activacion=\"relu\")\n",
        "\n",
        "        # Decoder Seccion:\n",
        "\n",
        "\n",
        "        self.decoder1=U_Net_block(512,512,\"up\",btchnm=True,activacion=\"relu\",dropout_on=True)\n",
        "        self.decoder2=U_Net_block(1024,512,\"up\",btchnm=True,activacion=\"relu\",dropout_on=True)\n",
        "        self.decoder3=U_Net_block(1024,512,\"up\",btchnm=True,activacion=\"relu\",dropout_on=True)\n",
        "        self.decoder4=U_Net_block(1024,512,\"up\",btchnm=True,activacion=\"relu\")\n",
        "        self.decoder5=U_Net_block(1024,256,\"up\",btchnm=True,activacion=\"relu\")\n",
        "        self.decoder6=U_Net_block(512,128,\"up\",btchnm=True,activacion=\"relu\")\n",
        "        self.decoder7=U_Net_block(256,64,\"up\",btchnm=True,activacion=\"relu\")\n",
        "\n",
        "\n",
        "        # Last\n",
        "        self.convlast=U_Net_block(128,2,\"up\",btchnm=False,activacion=\"relu\")\n",
        "\n",
        "        self.than=nn.Tanh()\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        d1=self.inicial(x) # d1 ->64 out\n",
        "        d2=self.encoder1(d1) # d2 ->128 out\n",
        "        d3=self.encoder2(d2) # d3 ->256 out\n",
        "        d4=self.encoder3(d3) # d4 ->512 out\n",
        "        d5=self.encoder4(d4) # d5 ->512 out\n",
        "        d6=self.encoder5(d5) # d6 ->512 out\n",
        "        d7=self.encoder6(d6) # d7 ->512 out\n",
        "\n",
        "        bneck=self.bottleneck(d7)  #bneck -> 512 out\n",
        "\n",
        "        e1=self.decoder1(bneck) #e1 -> 512 out\n",
        "\n",
        "        e2=self.decoder2(torch.cat([e1,d7],1)) # e2  in ->512+512=1024  out->512\n",
        "\n",
        "        e3=self.decoder3(torch.cat([e2,d6],1)) # e3  in ->512+512=1024   out->512\n",
        "\n",
        "        e4=self.decoder4(torch.cat([e3,d5],1)) # e4 in ->512+512=1024   out->512\n",
        "\n",
        "        e5=self.decoder5(torch.cat([e4,d4],1)) # e5 in ->512+512=1024    out->256\n",
        "\n",
        "        e6=self.decoder6(torch.cat([e5,d3],1)) # e6 in ->256+256=512   out->128\n",
        "\n",
        "        e7=self.decoder7(torch.cat([e6,d2],1)) # e7 in ->128+128=256  out->64\n",
        "\n",
        "        out=self.convlast(torch.cat([e7,d1],1)) # last in 64+64  out->3\n",
        "\n",
        "        out=self.than(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "TuQmnT8vZej0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *2) ** GENERADOR 512 X512 ENTRA L CANAL SALE 2 CANALES AB(OBLIGATORIO)\n",
        "\n",
        "#---------------------GENERADOR BASADO EN U- NET---------------------------------------------------\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "#input debe ser 80x80 otras dimeneoins  puede que tenega eror al mometno de concat las dimenes reducidas debe de conicidir y este unetblacok se ajsuta a una etnrada 256x256\n",
        "class U_Net_block(nn.Module):\n",
        "\n",
        "  def __init__(self,in_channel,out_channel,type,btchnm=True,activacion=\"leakyrelu\",dropout_on=\"False\"):\n",
        "   super(U_Net_block,self).__init__()\n",
        "\n",
        "   self.type=type\n",
        "   self.blockdown=nn.Conv2d(in_channel,out_channel,kernel_size=3,stride=1,padding=1,bias=False)\n",
        "   self.blockup=nn.Conv2d(in_channel,out_channel,kernel_size=3,stride=1,padding=1,bias=False)\n",
        "   self.maxpool=nn.MaxPool2d(2,2)\n",
        "   self.batchnorm=nn.BatchNorm2d(out_channel)\n",
        "\n",
        "   self.activacion=activacion\n",
        "   self.leakyrelu=nn.LeakyReLU(0.2)\n",
        "   self.relu=nn.ReLU()\n",
        "   self.btchnm_on=btchnm\n",
        "   self.btchnorm=nn.BatchNorm2d(out_channel)\n",
        "   self.dropout_on=dropout_on # solo si necsitmos usar el dropout\n",
        "\n",
        "   self.dropout=nn.Dropout(0.5)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    if self.type==\"down\" :\n",
        "     x=self.blockdown(x)\n",
        "     x=self.maxpool(x)\n",
        "\n",
        "    elif self.type==\"up\":\n",
        "     x=self.blockup(x)\n",
        "     x=F.interpolate(x,scale_factor=2, mode='bilinear', align_corners=False)\n",
        "\n",
        "\n",
        "    if self.btchnm_on==True:\n",
        "     x=self.btchnorm(x)\n",
        "\n",
        "    if(self.activacion==\"leakyrelu\"):\n",
        "      out=self.leakyrelu(x)\n",
        "    else:\n",
        "      out=self.relu(x)\n",
        "\n",
        "    if(self.dropout_on==True):\n",
        "      out=self.dropout(x)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "class Generator_U_Net(nn.Module):\n",
        "\n",
        "    def __init__(self,in_channel=3):\n",
        "        super(Generator_U_Net,self).__init__()\n",
        "\n",
        "        # Encoder Seccion:\n",
        "\n",
        "        self.inicial=U_Net_block(1,32,\"down\",btchnm=False,activacion=\"leakyrelu\")\n",
        "        self.segundo=U_Net_block(32,32,\"down\",btchnm=True,activacion=\"leakyrelu\")\n",
        "        self.encoder1=U_Net_block(32,128,\"down\",btchnm=True,activacion=\"leakyrelu\")\n",
        "        self.encoder2=U_Net_block(128,256,\"down\",btchnm=True,activacion=\"leakyrelu\")\n",
        "        self.encoder3=U_Net_block(256,512,\"down\",btchnm=True,activacion=\"leakyrelu\")\n",
        "        self.encoder4=U_Net_block(512,512,\"down\",btchnm=True,activacion=\"leakyrelu\")\n",
        "        self.encoder5=U_Net_block(512,512,\"down\",btchnm=True,activacion=\"leakyrelu\")\n",
        "        self.encoder6=U_Net_block(512,512,\"down\",btchnm=True,activacion=\"leakyrelu\")\n",
        "        self.encoder7=U_Net_block(512,512,\"down\",btchnm=True,activacion=\"leakyrelu\")\n",
        "\n",
        "        self.bottleneck=U_Net_block(512,512,\"down\",btchnm=False,activacion=\"relu\")\n",
        "\n",
        "        # Decoder Seccion:\n",
        "\n",
        "\n",
        "        self.decoder1=U_Net_block(512,512,\"up\",btchnm=True,activacion=\"relu\",dropout_on=True)\n",
        "        self.decoder2=U_Net_block(1024,512,\"up\",btchnm=True,activacion=\"relu\",dropout_on=True)\n",
        "        self.decoder3=U_Net_block(1024,512,\"up\",btchnm=True,activacion=\"relu\",dropout_on=True)\n",
        "        self.decoder4=U_Net_block(1024,512,\"up\",btchnm=True,activacion=\"relu\")\n",
        "        self.decoder5=U_Net_block(1024,256,\"up\",btchnm=True,activacion=\"relu\")\n",
        "        self.decoder6=U_Net_block(512,128,\"up\",btchnm=True,activacion=\"relu\")\n",
        "        self.decoder7=U_Net_block(256,64,\"up\",btchnm=True,activacion=\"relu\")\n",
        "        self.decoder8=U_Net_block(96,32,\"up\",btchnm=True,activacion=\"relu\")\n",
        "\n",
        "        # Last\n",
        "        self.convlast=U_Net_block(64,2,\"up\",btchnm=False,activacion=\"relu\")\n",
        "\n",
        "        self.than=nn.Tanh()\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        d0=self.inicial(x) # d1 ->64 out\n",
        "        d1=self.segundo(d0) # d1 ->64 out\n",
        "\n",
        "        d2=self.encoder1(d1) # d2 ->128 out\n",
        "        d3=self.encoder2(d2) # d3 ->256 out\n",
        "        d4=self.encoder3(d3) # d4 ->512 out\n",
        "        d5=self.encoder4(d4) # d5 ->512 out\n",
        "        d6=self.encoder5(d5) # d6 ->512 out\n",
        "        d7=self.encoder6(d6) # d7 ->512 out\n",
        "\n",
        "        bneck=self.bottleneck(d7)  #bneck -> 512 out\n",
        "\n",
        "        e1=self.decoder1(bneck) #e1 -> 512 out\n",
        "\n",
        "        e2=self.decoder2(torch.cat([e1,d7],1)) # e2  in ->512+512=1024  out->512\n",
        "\n",
        "        e3=self.decoder3(torch.cat([e2,d6],1)) # e3  in ->512+512=1024   out->512\n",
        "\n",
        "        e4=self.decoder4(torch.cat([e3,d5],1)) # e4 in ->512+512=1024   out->512\n",
        "\n",
        "        e5=self.decoder5(torch.cat([e4,d4],1)) # e5 in ->512+512=1024    out->256\n",
        "\n",
        "        e6=self.decoder6(torch.cat([e5,d3],1)) # e6 in ->256+256=512   out->128\n",
        "\n",
        "        e7=self.decoder7(torch.cat([e6,d2],1)) # e7 in ->128+128=256  out->64\n",
        "        e8=self.decoder8(torch.cat([e7,d1],1)) # e7 in ->128+128=256  out->64\n",
        "\n",
        "        out=self.convlast(torch.cat([e8,d0],1)) # last in 64+64  out->3\n",
        "\n",
        "        out=self.than(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "vmWCUNlRUc6c",
        "cellView": "form"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *2) ** Prototipo WaveNet GENERADOR 256x256 ENTRA L CANAL SALE 2 CANALES AB(OBLIGATORIO)\n",
        "\n",
        "#---------------------GENERADOR BASADO EN U- NET---------------------------------------------------\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "#input debe ser 80x80 otras dimeneoins  puede que tenega eror al mometno de concat las dimenes reducidas debe de conicidir y este unetblacok se ajsuta a una etnrada 256x256\n",
        "class U_Net_block(nn.Module):\n",
        "\n",
        "  def __init__(self,in_channel,out_channel,type,btchnm=True,activacion=\"leakyrelu\",dropout_on=\"False\"):\n",
        "   super(U_Net_block,self).__init__()\n",
        "\n",
        "   self.type=type\n",
        "   self.blockdown=nn.Conv2d(in_channel,out_channel,kernel_size=4,stride=2,padding=1,bias=False)\n",
        "   self.blockup=nn.Conv2d(in_channel,out_channel,kernel_size=3,stride=1,padding=1,bias=False)\n",
        "   self.batchnorm=nn.BatchNorm2d(out_channel)\n",
        "\n",
        "   self.activacion=activacion\n",
        "   self.leakyrelu=nn.LeakyReLU(0.2)\n",
        "   self.relu=nn.ReLU()\n",
        "   self.batch_on=btchnm\n",
        "   self.batchnorm=nn.BatchNorm2d(out_channel)\n",
        "   self.dropout_on=dropout_on # solo si necsitmos usar el dropout\n",
        "\n",
        "   self.dropout=nn.Dropout(0.5)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    if self.type==\"down\" :\n",
        "     x=self.blockdown(x)\n",
        "\n",
        "    elif self.type==\"up\":\n",
        "     x=self.blockup(x)\n",
        "     x=F.interpolate(x,scale_factor=2, mode='bilinear', align_corners=False)\n",
        "\n",
        "\n",
        "    if self.batch_on==True:\n",
        "     x=self.batchnorm(x)\n",
        "\n",
        "    if(self.activacion==\"leakyrelu\"):\n",
        "      out=self.leakyrelu(x)\n",
        "    else:\n",
        "      out=self.relu(x)\n",
        "\n",
        "    if(self.dropout_on==True):\n",
        "      out=self.dropout(x)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "class Generator_U_Net(nn.Module):\n",
        "\n",
        "    def __init__(self,in_channel=3):\n",
        "        super(Generator_U_Net,self).__init__()\n",
        "\n",
        "\n",
        "        # Encoder Seccion:\n",
        "        self.encoderInicial=U_Net_block(1,128,\"down\",btchnm=False,activacion=\"leakyrelu\")\n",
        "\n",
        "        self.decoder1=U_Net_block(128,64,\"up\",btchnm=True,activacion=\"relu\")#matiene con le f.interpole luego se aumetara las dimiensionesx2\n",
        "        self.encoder1=U_Net_block(64,128,\"down\",btchnm=True,activacion=\"leakyrelu\") #128x128\n",
        "        self.encoder2=U_Net_block(128,256,\"down\",btchnm=True,activacion=\"leakyrelu\")#64x64\n",
        "\n",
        "        self.decoder2=U_Net_block(256,128,\"up\",btchnm=True,activacion=\"relu\")#128x128\n",
        "\n",
        "\n",
        "        # Last\n",
        "        self.decoderFinal=U_Net_block(128,2,\"up\",btchnm=False,activacion=\"relu\")#matiene con le f.interpole luego se aumetara las dimiensionesx2\n",
        "\n",
        "        self.than=nn.Tanh()\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        inicial=self.encoderInicial(x)\n",
        "\n",
        "        d1=self.decoder1(inicial)\n",
        "        e1=self.encoder1(d1)\n",
        "        e2=self.encoder2(e1)\n",
        "        d2=self.decoder2(e2)\n",
        "\n",
        "        out=self.decoderFinal(d2)\n",
        "        out=self.than(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "qe2UvGyIbArm",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fHbQ0rR8nfPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *2) ** Prototipo WaveNet GENERADOR 256x256 CON SKIP CONECTION ENTRA L CANAL SALE 2 CANALES AB(OBLIGATORIO)\n",
        "\n",
        "#---------------------GENERADOR BASADO EN U- NET---------------------------------------------------\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "#input debe ser 80x80 otras dimeneoins  puede que tenega eror al mometno de concat las dimenes reducidas debe de conicidir y este unetblacok se ajsuta a una etnrada 256x256\n",
        "class U_Net_block(nn.Module):\n",
        "\n",
        "  def __init__(self,in_channel,out_channel,type,btchnm=True,activacion=\"leakyrelu\",dropout_on=\"False\"):\n",
        "   super(U_Net_block,self).__init__()\n",
        "\n",
        "   self.type=type\n",
        "   self.blockdown=nn.Conv2d(in_channel,out_channel,kernel_size=4,stride=2,padding=1,bias=False)\n",
        "   self.blockup=nn.Conv2d(in_channel,out_channel,kernel_size=3,stride=1,padding=1,bias=False)\n",
        "   self.batchnorm=nn.BatchNorm2d(out_channel)\n",
        "\n",
        "   self.activacion=activacion\n",
        "   self.leakyrelu=nn.LeakyReLU(0.2)\n",
        "   self.relu=nn.ReLU()\n",
        "   self.batch_on=btchnm\n",
        "   self.btchnorm=nn.BatchNorm2d(out_channel)\n",
        "   self.dropout_on=dropout_on # solo si necsitmos usar el dropout\n",
        "\n",
        "   self.dropout=nn.Dropout(0.5)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    if self.type==\"down\" :\n",
        "     x=self.blockdown(x)\n",
        "\n",
        "    elif self.type==\"up\":\n",
        "     x=self.blockup(x)\n",
        "     x=F.interpolate(x,scale_factor=2, mode='bilinear', align_corners=False)\n",
        "\n",
        "\n",
        "    if self.batch_on==True:\n",
        "     x=self.btchnorm(x)\n",
        "\n",
        "    if(self.activacion==\"leakyrelu\"):\n",
        "      out=self.leakyrelu(x)\n",
        "    else:\n",
        "      out=self.relu(x)\n",
        "\n",
        "    if(self.dropout_on==True):\n",
        "      out=self.dropout(x)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "class Generator_U_Net(nn.Module):\n",
        "\n",
        "    def __init__(self,in_channel=3):\n",
        "        super(Generator_U_Net,self).__init__()\n",
        "\n",
        "\n",
        "        # Encoder Seccion:\n",
        "        self.encoderInicial=U_Net_block(1,128,\"down\",btchnm=False,activacion=\"leakyrelu\")\n",
        "\n",
        "        self.decoder1=U_Net_block(128,64,\"up\",btchnm=True,activacion=\"relu\")#matiene con le f.interpole luego se aumetara las dimiensionesx2\n",
        "        self.encoder1=U_Net_block(64,128,\"down\",btchnm=False,activacion=\"leakyrelu\") #128x128\n",
        "        self.encoder2=U_Net_block(256,256,\"down\",btchnm=False,activacion=\"leakyrelu\")#64x64\n",
        "\n",
        "        self.decoder2=U_Net_block(256,128,\"up\",btchnm=True,activacion=\"relu\")#128x128\n",
        "\n",
        "\n",
        "        # Last\n",
        "        self.decoderFinal=U_Net_block(256,2,\"up\",btchnm=False,activacion=\"relu\")#matiene con le f.interpole luego se aumetara las dimiensionesx2\n",
        "\n",
        "        self.than=nn.Tanh()\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "\n",
        "        inicial=self.encoderInicial(x)\n",
        "\n",
        "        d1=self.decoder1(inicial)\n",
        "        e1=self.encoder1(d1)\n",
        "        e2=self.encoder2(torch.cat([inicial,e1],1))\n",
        "        d2=self.decoder2(e2)\n",
        "\n",
        "        out=self.decoderFinal(torch.cat([inicial,d2],1))\n",
        "        out=self.than(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qz1tVDA6mKUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VAMOS A VER QUE MEDIADES EL GENERADOR DA COMO RESUTLADO CON LW RESOLUTIONS MEDIDAES:\n",
        "\n",
        "generador=Generator_U_Net(1)\n",
        "generador=generador.to(device)\n",
        "x=torch.randn(20,1,512,512).to(device)\n",
        "\n",
        "print(generador(x).shape)"
      ],
      "metadata": {
        "id": "Fyh-XN-zamlm",
        "outputId": "37783643-edfe-41e5-9d88-84a5ad2d2bae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 2, 512, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PROBAMOS EL GENERADOR INCIAL:\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------\n",
        "def show_comparacion(real,generado): #deben de ingrenar don tennoren de imagen generada y real\n",
        " print(generado.shape)\n",
        " print(real.shape)\n",
        " real=real.detach().squeeze().cpu().numpy().transpose(1, 2, 0)\n",
        " generado=generado.squeeze().cpu().detach().numpy().transpose(1, 2, 0)\n",
        "# Primer subgráfico: imagen original\n",
        " plt.subplot(1, 2, 1)\n",
        " plt.imshow(generado)  # Convertir a NumPy y transponer dimensiones\n",
        " plt.title('Imagen Generada')\n",
        " plt.axis('off')\n",
        "\n",
        "# Segundo subgráfico: imagen transformada\n",
        " plt.subplot(1, 2, 2)\n",
        " plt.imshow(real)  # Convertir a NumPy y transponer dimensiones\n",
        " plt.title('Imagen Real')\n",
        " plt.axis('off')\n",
        "\n",
        "# Ajustar el diseño para evitar superposición de títulos\n",
        " plt.tight_layout()\n",
        "\n",
        "# Mostrar la figura\n",
        " plt.show()\n",
        "\n",
        "\n",
        " plt.figure(figsize=(10, 5))\n",
        "#-----------------------------------------------------------------------------------\n",
        "generador=Generator_U_Net().to(\"cpu\")\n",
        "\n",
        "\n",
        "ruta_imagen = \"/content/imagenes/transformed_0002_0.png\"\n",
        "imagen = Image.open(ruta_imagen)\n",
        "\n",
        "transformaciones = transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "#original iamgen tensor\n",
        "tensor_imagen = transformaciones(imagen).unsqueeze(0)\n",
        "tensor_imagen=tensor_imagen.to(\"cpu\")\n",
        "\n",
        "#imagen generada\n",
        "imagen_generada=generador(tensor_imagen)\n",
        "print(imagen_generada.shape)\n",
        "imagen_numpy = imagen_generada.squeeze().detach().numpy()\n",
        "\n",
        "# Mostrar la imagen utilizando matplotlib\n",
        "plt.imshow(imagen_numpy.transpose(1, 2, 0))  # cmap='gray' es para mostrar la imagen en escala de grises\n",
        "plt.axis('off')  # Ocultar ejes\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UjlYRf2XYly3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "#vamos a extraer los feature es decir las caracteisicas imporantes que exiten entre ambas imagnes y compraralas esto se usara par luego hace rel loss contet apartir del contendio\n",
        "\n",
        "class Feature_Extractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Feature_Extractor, self).__init__()\n",
        "        # Cargar un modelo VGG-19 preentrenado\n",
        "        vgg19_model = models.vgg16(pretrained=True).features.eval()\n",
        "\n",
        "        # No actualizar los pesos del modelo VGG durante el entrenamiento\n",
        "        for param in vgg19_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        selected_layers = list(vgg19_model.children())[:31] #AGREGAMOS EL VGG HASTA VERFICAR QUE EL ULITMA CAPA NO TENGA RELU\n",
        "\n",
        "        self.vgg=nn.Sequential(*selected_layers)\n",
        "\n",
        "    def forward(self, img):\n",
        "\n",
        "        # Extraer características de las imágenes generada y real\n",
        "        feature_img = self.vgg(img)\n",
        "\n",
        "        return feature_img\n",
        "\n",
        "\n",
        "# TV Loss se utiliza comúnmente en tareas de generación de imágenes para reducir el ruido y fomentar la suavidad en las imágenes generadas.\n",
        "\n",
        "class TVLoss(nn.Module):\n",
        "  def __init__(self, tv_loss_weight=1):\n",
        "    super(TVLoss, self).__init__()\n",
        "    self.tv_loss_weight=tv_loss_weight\n",
        "  def forward(self, x):\n",
        "    batch_size=x.size()[0]\n",
        "    h_x = x.size()[2]\n",
        "    w_x = x.size()[3]\n",
        "\n",
        "    count_h = self.tensor_size(x[:, :, 1:, :])\n",
        "    count_w = self.tensor_size(x[:, :, :, 1:])\n",
        "\n",
        "\n",
        "    h_tv = torch.pow(x[:, :, 1:, :] - x[:, :, :h_x - 1, :], 2).sum()\n",
        "    w_tv = torch.pow(x[:, :, :, 1:] - x[:, :, :, :w_x - 1], 2).sum()\n",
        "    return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
        "\n",
        "  # Forgot to implement an important method\n",
        "  @staticmethod # Must add this\n",
        "  def tensor_size(t):\n",
        "    return t.size()[1] * t.size()[2] * t.size()[3]\n",
        "\n",
        "\n",
        "def psnr(image1, image2):\n",
        "    mse = torch.mean((image1 - image2) ** 2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    max_pixel = 1\n",
        "    psnr_value = 10 * torch.log10((max_pixel ** 2) / mse)\n",
        "    return psnr_value\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cnWH1y8fEpTb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NFKcAGSnZYEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg=Feature_Extractor()\n",
        "print(vgg)\n",
        "tv_loss= TVLoss()\n",
        "x=torch.randn(18,3,60,60)\n",
        "tv_loss=tv_loss(x)\n",
        "\n",
        "print(tv_loss)"
      ],
      "metadata": {
        "id": "AIEYS7UZNql6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.utils as vutils\n",
        "import sklearn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "from tqdm import tqdm\n",
        "# ...\n",
        "\n",
        "#d=Discriminator(image_dim).to(device)\n",
        "#g=Generador(dim_vector_ruido,image_dim).to(device)\n",
        "\n",
        "#d.load_state_dict(torch.load(\"/content/modelo_gatos_d.pt\"))\n",
        "#g.load_state_dict(torch.load(\"/content/modelo_gatos_g.pt\"))\n",
        "\n",
        "#d=d.to(device)\n",
        "#g=g.to(device)\n",
        "\n",
        "\n",
        "# Supongamos que ya has definido las instancias de los modelos Generador (g) y Discriminador (d),\n",
        "# y has configurado los optimizadores (g_optimizer y d_optimizer) y la función de pérdida (criterio).\n",
        "\n",
        "\n",
        "\n",
        "def GAN(discriminador, generador, data_loader, num_epochs, batch_size, criterio_g,criterio_d, d_optimizador, g_optimizador, device):\n",
        "\n",
        "    discriminador=discriminador.to(device)\n",
        "    generador=generador.to(device)\n",
        "    feature_extractor=Feature_Extractor().to(device)\n",
        "    tv_loss= TVLoss().to(device)\n",
        "    L1=nn.L1Loss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        resultados = { 'd_loss':[],\"g_loss\":[], \"d_score\":[], \"psnr\":[]}\n",
        "        data_loader = tqdm(data_loader)\n",
        "\n",
        "        for  (l, ab) in (data_loader):\n",
        "\n",
        "            l=l.float().to(device)\n",
        "            ab=ab.float().to(device)\n",
        "\n",
        "            generador.eval()\n",
        "            discriminador.train()\n",
        "\n",
        "            # Entrenar el discriminador con imágenes reales\n",
        "            d_optimizador.zero_grad()\n",
        "\n",
        "            prediction_real = discriminador(l.float(),ab)\n",
        "\n",
        "            real_loss = criterio_d(prediction_real, torch.ones_like(prediction_real).to(device))\n",
        "\n",
        "\n",
        "            # Entrenar el discriminador con imágenes generadas\n",
        "\n",
        "            fake_ab = generador(l)\n",
        "\n",
        "            prediction_fake = discriminador(l,fake_ab.float().detach())\n",
        "\n",
        "            fake_loss = criterio_d(prediction_fake, torch.zeros_like(prediction_fake).to(device)).to(device)\n",
        "            discriminator_loss = (real_loss + fake_loss)/2\n",
        "\n",
        "            discriminator_loss.backward()\n",
        "\n",
        "            d_optimizador.step()\n",
        "\n",
        "            # Entrenar el generador\n",
        "            generador.train()\n",
        "            discriminador.eval()\n",
        "            g_optimizador.zero_grad()\n",
        "\n",
        "            generated_ab = generador(l.detach())\n",
        "\n",
        "            d_fake=discriminador(l,generated_ab)\n",
        "\n",
        "            loss_gan=criterio_g(d_fake,torch.ones_like(d_fake).to(device)) #loss del generador aparitr del disicmirnador que dice si es o no una imagen falsa\n",
        "            loss_g=L1(ab,generated_ab)\n",
        "\n",
        "            generator_loss = (100*loss_g)+loss_gan\n",
        "            generator_loss.backward()\n",
        "            g_optimizador.step()\n",
        "\n",
        "\n",
        "            #resultados por batch:\n",
        "            resultados[\"d_loss\"].append(discriminator_loss.item())\n",
        "            resultados[\"g_loss\"].append(generator_loss.item())\n",
        "\n",
        "\n",
        "            data_loader.set_description(desc=\"[%d/%d] Loss_D: %.4f Loss_G: %.4f psnr: %.4f\" % (\n",
        "            epoch, num_epochs, np.mean(resultados['d_loss']),\n",
        "            np.mean(resultados['g_loss']) ,\n",
        "            np.mean( resultados['psnr']) ,\n",
        "\n",
        "              ))\n",
        "\n",
        "        # Imprimir estadísticas y visualizar imágenes generadas al final de cada época\n",
        "        print(f'Época [{epoch}/{num_epochs}] '\n",
        "                      f'Pérdida del Discriminador: {np.mean(resultados[\"d_loss\"]):.4f}, '\n",
        "                      f'Pérdida del Generador: {np.mean(resultados[\"g_loss\"]):.4f}',f'psnr:{np.mean(resultados[\"psnr\"]):.4f}')\n",
        "        with torch.no_grad():\n",
        "\n",
        "            generador.eval()\n",
        "\n",
        "            ab_test = generador(l).detach()\n",
        "\n",
        "            generado_ab=ab_test[0].squeeze().cpu().detach().numpy().transpose(1, 2, 0)\n",
        "            l_test = l[0].squeeze().cpu().numpy()\n",
        "            ab_test=ab[0].squeeze().cpu().numpy().transpose(1, 2, 0)\n",
        "\n",
        "            ab_test_desnormalizado=((((ab_test+1)/2)*255))-128\n",
        "            ab_desnormalizado=((((generado_ab+1)/2)*255))-128\n",
        "            l1_desnormalizado=l_test*100\n",
        "\n",
        "            plt.figure(figsize=(20, 5))\n",
        "            # Subfigura generada ab\n",
        "            plt.subplot(1, 4, 1)\n",
        "            img_rgb = estructura_imagen  # crea un array de ceros para la imagen RGB\n",
        "\n",
        "            img_rgb[:,:,1:] =ab_desnormalizado\n",
        "            plt.imshow(img_rgb)\n",
        "            plt.title('imagen generada')\n",
        "\n",
        "            # Subfigura generada rgb\n",
        "            plt.subplot(1, 4, 2)\n",
        "            img_rgb = estructura_imagen  # crea un array de ceros para la imagen RGB\n",
        "            img_rgb[:,:,0]=l1_desnormalizado\n",
        "            img_rgb[:,:,1:] =ab_desnormalizado\n",
        "            plt.imshow(lab2rgb(img_rgb))\n",
        "            plt.title('imagen generada')\n",
        "\n",
        "\n",
        "            # Subfigura real ab\n",
        "            plt.subplot(1, 4, 3)\n",
        "            img_rgb2 = estructura_imagen  # crea un array de ceros para la imagen RGB\n",
        "            #img_rgb2[:,:,0]=l1_desnormalizado\n",
        "            img_rgb2[:,:,1:] = ab_test_desnormalizado\n",
        "            plt.imshow(img_rgb2)\n",
        "            plt.title('imagen real')\n",
        "\n",
        "            # Subfigura real rgb\n",
        "            plt.subplot(1, 4, 4)\n",
        "            img_rgb2 = estructura_imagen  # crea un array de ceros para la imagen RGB\n",
        "            img_rgb2[:,:,0]=l1_desnormalizado\n",
        "            img_rgb2[:,:,1:] = ab_test_desnormalizado\n",
        "            plt.imshow(lab2rgb(img_rgb2))\n",
        "            plt.title('imagen real')\n",
        "\n",
        "           # Ajustar diseño\n",
        "            plt.tight_layout()\n",
        "\n",
        "          # Mostrar las imágenes\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "num_epochs=31\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "d=Discriminator()\n",
        "g=Generator_U_Net(1)\n",
        "\n",
        "#d.load_state_dict(torch.load(\"/content/colorgan_d.pt\"))\n",
        "#g.load_state_dict(torch.load(\"/content/colorgan_g.pt\"))\n",
        "\n",
        "lr_g = 0.000008\n",
        "lr_d = 0.000008\n",
        "d_optimizer=optim.Adam(d.parameters(),lr=lr_d, betas=(0.5, 0.999))\n",
        "g_optimizer=optim.Adam(g.parameters(),lr=lr_g, betas=(0.5, 0.999))\n",
        "\n",
        "criterio_d=nn.BCELoss()\n",
        "criterio_g=nn.BCELoss()\n",
        "\n",
        "\n",
        "print(f\"learning rate discrimiador:{lr_d}\")\n",
        "print(f\"learning rate generador:{lr_g}\")\n",
        "\n",
        "GAN(d,g,data_loader,num_epochs,batch_size,criterio_g,criterio_d,d_optimizer,g_optimizer,device)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xOaEJmpkzNvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cJ6c47Md9cJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(g.state_dict(), 'colorgan_g.pt')\n",
        "torch.save(d.state_dict(), 'colorgan_d.pt')"
      ],
      "metadata": {
        "id": "nUbOcTLlt8m2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "while(1):\n",
        "  data.append('1234')"
      ],
      "metadata": {
        "id": "3I9v1oNc8QI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "8XIzNqOTzwZW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0kTVzpjZvFy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d.load_state_dict(torch.load(\"/content/srgan_d.pt\"))"
      ],
      "metadata": {
        "id": "7U056UsVyqpo",
        "outputId": "20208f3a-51c8-41a3-c6fe-64a605425f43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import skimage.io\n",
        "# Suponiendo que \"Generador\" es la clase de tu generador y \"ruta_modelo\" es la ruta del modelo guardado\n",
        "generador = Generator_U_Net(1)  # creando generado\n",
        "generador.load_state_dict(torch.load(\"/content/colorgan_g.pt\"))\n",
        "generador.to(device)\n",
        "generador.eval()\n",
        "\n",
        "ruta_imagen = \"/content/dataset/animes/Image_88.png\"\n",
        "imagen_pil = Image.open(ruta_imagen).convert(\"RGB\")\n",
        "\n",
        "\n",
        "lab_image=rgb2lab(imagen_pil)\n",
        "\n",
        "# Separa los canales L y AB\n",
        "l_channel = lab_image[:,:, 0]\n",
        "\n",
        "l_channel=l_channel/100 #normalizar l1\n",
        "\n",
        "transformaciones = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convierte la imagen a un tensor\n",
        "    transforms.Resize((512,512),interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "])\n",
        "\n",
        "l_tensor = transformaciones(l_channel)\n",
        "l_tensor=l_tensor.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    generador.eval()\n",
        "\n",
        "    generated_ab = generador(l_tensor.detach().float().unsqueeze(0)).squeeze().cpu().numpy().transpose(1, 2, 0)\n",
        "    ab_desnormalizado=((((generated_ab+1)/2)*255))-128\n",
        "\n",
        "    img_rgb = np.zeros((512, 512, 3), dtype=np.float64)  # crea un array de ceros para la imagen RGB\n",
        "    img_rgb[:,:,0]=l_tensor.squeeze().detach().cpu().numpy()*100\n",
        "    img_rgb[:,:,1:] = ab_desnormalizado\n",
        "\n",
        "    img_rgb=lab2rgb(img_rgb)\n",
        "\n",
        "\n",
        "# Visualizar la imagen generada\n",
        "plt.imshow(img_rgb)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "imagen_scaled = (img_rgb / np.max(img_rgb))*255 # como esta en float pil necsit valores rango 0-255\n",
        "\n",
        "# Convertir la imagen a tipo uint8\n",
        "\n",
        "imagen_uint8 = imagen_scaled.astype(np.uint8)\n",
        "\n",
        "# Crear una imagen PIL a partir del arreglo uint8\n",
        "imagen_pil = Image.fromarray(imagen_uint8)\n",
        "\n",
        "imagen_bicubic = imagen_pil.resize((imagen_pil.width , imagen_pil.height), resample=Image.BICUBIC)\n",
        "# Guardar la imagen en disco\n",
        "imagen_bicubic.save(\"imagen_pil.png\")"
      ],
      "metadata": {
        "id": "k3ANH_wEuUBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zsKMKpDSHrIm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}