{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYbWeBK4eq5wIoER9AhBKw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuniorHZ19/HerramientasIA/blob/main/caragatov1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hsgw-_4AS6fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *0) ** Instalando libreria(OBLIGATORIO)\n",
        "\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install google_images_download"
      ],
      "metadata": {
        "id": "R0Je-JZAxuYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *1) ** Descargando DataSet  caras gatos(OBLIGATORIO)\n",
        "import zipfile\n",
        "\n",
        "nombre_zip=\"data_set_gatos.zip\"\n",
        "\n",
        "directorio_destino=\"/content/\"\n",
        "\n",
        "!gdown --id 1EK7H_QJqxDy0wBssMEi2_gWdo3zE2pmQ -O {nombre_zip}\n",
        "\n",
        "with zipfile.ZipFile(nombre_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directorio_destino)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxzaMyUeTGCC",
        "outputId": "5c386b3e-561c-4a76-b19f-f55262e452e8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1EK7H_QJqxDy0wBssMEi2_gWdo3zE2pmQ\n",
            "To: /content/data_set_gatos.zip\n",
            "100% 284M/284M [00:04<00:00, 59.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *1) ** Clase Para manejo de directorios de datasets de imagenes\n",
        "\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "# Recorre el directorio  y elmiina los archvios que no tiene las extensioens permitidas\n",
        "\n",
        "class DataSetManage:\n",
        "\n",
        " def comprobar_ext_directorios(self,directorios):\n",
        "\n",
        "  for clase,[directorio,etiquetas] in(directorios.items()):\n",
        "   lista_directorio=os.listdir(directorio)\n",
        "   self.validarExt(directorio)\n",
        "\n",
        "\n",
        "\n",
        " def  validarExt(self,directorio):\n",
        "  print(directorio)\n",
        "   # Extensiones permitidas\n",
        "  extensiones_permitidas = {\".jpg\", \".jpeg\", \".png\"}\n",
        "  for root, dirs, files in os.walk(directorio):\n",
        "\n",
        "    for file in files:\n",
        "        # Obtiene la extensión del archivo\n",
        "        _, extension = os.path.splitext(file)\n",
        "\n",
        "        # Verifica si la extensión no está en la lista de extensiones permitidas y elimina el archivo\n",
        "        if extension.lower() not in extensiones_permitidas:\n",
        "            archivo_a_eliminar = os.path.join(root, file)\n",
        "            os.remove(archivo_a_eliminar)\n",
        "            print(f\"Se eliminó: {archivo_a_eliminar}\")\n",
        "\n",
        "\n",
        "# Cambia nombre de cada archivo dentro del directorio a un valor secuencial\n",
        "\n",
        " def cambiar_nombres_directorios(self,directorios):\n",
        "   for clase,[directorio,etiquetas] in(directorios.items()):\n",
        "     lista_directorio=os.listdir(directorio)\n",
        "     self.cambiarNombre(directorio,clase)\n",
        "\n",
        "\n",
        " def cambiarNombre(self,directorio,subfijo):\n",
        "  archivos_en_directorio = os.listdir(directorio)\n",
        "  for i, archivo in enumerate(archivos_en_directorio, start=1):\n",
        "    # Construir el nuevo nombre del archivo\n",
        "    nuevo_nombre = f\"{subfijo}{i}{os.path.splitext(archivo)[1]}\"\n",
        "\n",
        "    # Ruta completa del archivo antiguo y nuevo\n",
        "    ruta_antigua = os.path.join(directorio, archivo)\n",
        "    ruta_nueva = os.path.join(directorio, nuevo_nombre)\n",
        "\n",
        "    # Cambiar el nombre del archivo\n",
        "    os.rename(ruta_antigua, ruta_nueva)\n",
        "    print(f\"Se cambió el nombre de {ruta_antigua} a {ruta_nueva}\")\n",
        "\n",
        "\n",
        "#Obtiene la cantidad de elemntos que tiene la carpeta\n",
        "\n",
        " def len_directorio(self,directorio):\n",
        "    cantidad_elementos = sum(1 for elemento in os.listdir(directorio) if os.path.isfile(os.path.join(directorio, elemento)))\n",
        "    return cantidad_elementos\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------------------------------\n",
        "\n",
        "#Valida si la imagen se puede leer usando  pill o cv2 si no se puede leer se elimina\n",
        "\n",
        " def validar_Img_Pill(self,directorios,):\n",
        "  for etiqueta,[directorio,clase] in(directorios.items()):\n",
        "\n",
        "    lista_paths=os.listdir(directorio)\n",
        "    self.validarLecturaImgPill(directorio,lista_paths)\n",
        "  print(f\"Se ah validado todas las imagenes\")\n",
        "\n",
        " def validar_Img_cv2(self,directorios):\n",
        "  for etiqueta,[directorio,clase] in(directorios.items()):\n",
        "\n",
        "    lista_paths=os.listdir(directorio)\n",
        "    self.validarLecturaImg(directorio,lista_paths)\n",
        "  print(f\"Se ah validado todas las imagenes\")\n",
        "\n",
        "\n",
        " def validarLecturaImg(self,directorio,lista):\n",
        "\n",
        "  for ruta in(lista):\n",
        "   imagen=cv2.imread(directorio+ruta)\n",
        "   if  imagen is None:\n",
        "     os.remove(directorio+ruta)\n",
        "     print(f\"No se pudo leer y se elimino archivo:{directorio+ruta}\")\n",
        "\n",
        " def validarLecturaImgPill(self,directorio,lista):\n",
        "    for ruta in(lista):\n",
        "     try:\n",
        "      imagen=Image.open(directorio+ruta)\n",
        "     except Exception as e:\n",
        "      os.remove(directorio+ruta)\n",
        "      print(f\"Archivo '{directorio+ruta}' eliminado.\")\n",
        "\n",
        "\n",
        "\n",
        "#vamos a recorrer el dicionario y validar ruta por ruta si se puede leer sino se elminara\n",
        "#vamos guaradno al mismo tiempo 3 listas, los directorios , listas de paths de los directiros y de las clases ,para usarlo luego usarlo al crear el csv\n",
        "\n",
        " def separar_datos_directorios(self,directorios):\n",
        "  listas_directorios=[]\n",
        "  listas_listas_directorios=[]\n",
        "  listas_clases=[]\n",
        "\n",
        "  for etiqueta,[directorio,clase] in(directorios.items()):\n",
        "\n",
        "       lista_paths=os.listdir(directorio)\n",
        "       listas_directorios.append(directorio)\n",
        "       listas_listas_directorios.append(lista_paths)\n",
        "       listas_clases.append(clase)\n",
        "\n",
        "  return listas_directorios,listas_listas_directorios,listas_clases\n",
        "\n",
        " def emparejar_listas_paths(self,lista_listas):\n",
        "\n",
        "   #Tomamos el minimo tamaño dentro de las lista de cada clase\n",
        "   tamaño_minimo = min(len(arr) for arr in lista_listas)\n",
        "\n",
        "   #Vamos a emparejar todas las listas con un tamaño igual que sea la del minimo tamaño de todas,esto para tener un set de datos parejo por cada clase\n",
        "   Reducido_lista_paths=[]\n",
        "\n",
        "   #Reduce cada lista de los paths a la cantidad minimo para que todos tenga iaugal cantidad\n",
        "   for listas in(lista_listas):\n",
        "    Reducido_lista_paths.append(listas[:tamaño_minimo])\n",
        "\n",
        "   return Reducido_lista_paths\n",
        "#---------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        " def crear_paths_csv(self,directorio_base,lista_paths,clases,nombre_archivo):\n",
        "\n",
        "   columnas=[\"path\",\"etiqueta\"]\n",
        "   datos_csv=[]\n",
        "\n",
        "   for dir_base,dir_path,clase in  zip(directorio_base,lista_paths,clases):\n",
        "\n",
        "    for path  in (dir_path):\n",
        "\n",
        "     datos_csv.append([dir_base+path ,clase])\n",
        "\n",
        "\n",
        "   df_lista=pd.DataFrame(datos_csv,columns=columnas)\n",
        "   df_lista.to_csv(nombre_archivo,index=False)\n",
        "   print(\"Csv Creado\")\n",
        "#---------------------------------------------------------------------------------\n",
        "\n",
        "#devuelve cuatnos elemtnos tiene cada clase\n",
        " def total_elementos(self,directorios,csv_path):\n",
        "    df=pd.read_csv(csv_path)\n",
        "    for clase,[directorio,etiqueta] in (directorios.items()):\n",
        "     tamaño_etiqueta=(df[\"etiqueta\"] == etiqueta).sum()\n",
        "     print(f\"la clase {clase} tiene :{tamaño_etiqueta} elementos\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4Byd3D3TT7Ov"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dmg=DataSetManage()\n",
        "\n",
        "directorios={\n",
        "     \"gato\":[\"/content/Cat-faces-dataset-master/dataset-part1/dataset-part1/\",1],\n",
        "     \"gato\":[\"/content/Cat-faces-dataset-master/dataset-part2/dataset-part2/\",1],\n",
        "     \"gato\":[\"/content/Cat-faces-dataset-master/dataset-part3/dataset-part3/\",1]\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "dmg.comprobar_ext_directorios(directorios)\n",
        "\n",
        "dmg.cambiar_nombres_directorios(directorios)\n",
        "\n",
        "dmg.validar_Img_Pill(directorios)\n",
        "\n",
        "listas_directorios,listas_paths_directorios,listas_clases=dmg.separar_datos_directorios(directorios)\n",
        "\n",
        "Reducido_lista_paths=dmg.emparejar_listas_paths(listas_paths_directorios)\n",
        "#validamos que todas las iamgnes en nuestro direcotrios puedan abrirse con openia cv2\n",
        "\n",
        "\n",
        "\n",
        "#La funcion que creamos para podre crear nuestro csv , con los parametros antes calucaldos que son 3 listas y el nombre del csv\n",
        "\n",
        "Dataset_csv=\"Data_set.csv\" #nombre que tendla nuestlo csv\n",
        "dmg.crear_paths_csv(listas_directorios,Reducido_lista_paths,listas_clases,Dataset_csv)\n",
        "\n",
        "#imprime total de elemtnos por clase\n",
        "dmg.total_elementos(directorios,\"/content/Data_set.csv\")"
      ],
      "metadata": {
        "id": "Kzybet7nU6gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *2) ** Creacion de clase DATASET(OBLIGATORIO)\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class MiDataSet(Dataset):\n",
        "\n",
        "  def __init__(self,csv_file, transform=None):\n",
        "\n",
        "\n",
        "     self.data=pd.read_csv(csv_file)\n",
        "\n",
        "     self.x=self.data[\"path\"]\n",
        "     self.y=self.data[\"etiqueta\"]\n",
        "\n",
        "     self.transform=transform\n",
        "\n",
        "     self.samples=self.data[\"path\"].shape[0]\n",
        "\n",
        "  def __getitem__(self,id):\n",
        "\n",
        "    rut_imagen=self.x[id]\n",
        "    imagen=cv2.imread(rut_imagen)\n",
        "    etiqueta=self.y[id]\n",
        "\n",
        "\n",
        "    if imagen is None:\n",
        "      pillow_image = Image.open(rut_imagen)\n",
        "      numpy_image = np.array(pillow_image)\n",
        "      imagen=cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "\n",
        "    imagen_rgb = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "    if self.transform:\n",
        "      imagen_rgb = self.transform(imagen_rgb)\n",
        "\n",
        "    return imagen_rgb,etiqueta\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "   return self.samples\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5vcmR_ZKhkGs"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "1WYVki2qv_EJ"
      },
      "outputs": [],
      "source": [
        "#@markdown # *0) ** Creando clase Discriminadora y Geneaadora:\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "class Discriminator (nn.Module):\n",
        "  def __init__(self,input_size):\n",
        "   super(Discriminator,self).__init__()\n",
        "\n",
        "   self.oculta1=nn.Linear(input_size,128)\n",
        "   self.salida= nn.Linear(128,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    x=self.oculta1(x)\n",
        "    x= nn.LeakyReLU(0.1)(x)\n",
        "\n",
        "    x=self.salida(x)\n",
        "    out=torch.sigmoid(x)\n",
        "\n",
        "    return out\n",
        "\n",
        "#------------------------------------------------------------------------\n",
        "class Generador(nn.Module):\n",
        "\n",
        "  def __init__(self,input_size,output_size):\n",
        "   super(Generador,self).__init__()\n",
        "\n",
        "   self.oculta1=nn.Linear(input_size,256)\n",
        "   self.salida= nn.Linear(256,output_size)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    x=self.oculta1(x)\n",
        "    x= nn.LeakyReLU(0.1)(x)\n",
        "\n",
        "    x=self.salida(x)\n",
        "    out=torch.Tanh(x)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA está disponible.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"CUDA no está disponible. Se utilizará la CPU.\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "transformaciones = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "    transforms.Resize((60, 60),antialias=True)\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "lr=0.000001\n",
        "batch_size=32\n",
        "dim_vector_ruido =80\n",
        "image_dim=60*60*3 #dimensiones de la imagen que entrara al discrimiador\n",
        "num_epochs=50\n",
        "\n",
        "\n",
        "Dataset=MiDataSet(\"/content/Data_set.csv\",transform=transformaciones)\n",
        "data_loader=DataLoader(Dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "\n",
        "d=Discriminator(image_dim).to(device)\n",
        "g=Generador(dim_vector_ruido,image_dim).to(device)\n",
        "\n",
        "fixed_noise=torch.randn((batch_size,dim_vector_ruido)).to(device)\n",
        "\n",
        "\n",
        "d_optimizer=optim.Adam(d.parameters(),lr=lr)\n",
        "g_optimizer=optim.Adam(g.parameters(),lr=lr)\n",
        "\n",
        "criterio=nn.BCELoss()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lvc112DWB-C",
        "outputId": "bf62fded-97fd-4980-8d22-96d2e434109c"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA no está disponible. Se utilizará la CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TuQmnT8vZej0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "# ...\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (x, y) in enumerate(data_loader):\n",
        "        g.train()  # g.train() y d.train() deben estar dentro del bucle de entrenamiento\n",
        "        d.train()\n",
        "\n",
        "        batch_size = y.size(0)\n",
        "        d_optimizer.zero_grad()  # Cambiado de d_optimisador a d_optimizer\n",
        "        real_images = x.view(-1, image_dim).to(device)\n",
        "        real_labels = y.view(-1, 1).float().to(device)  # Corregido el manejo de etiquetas reales\n",
        "        prediction_d = d(real_images)\n",
        "        real_loss = criterio(prediction_d, real_labels)\n",
        "        real_loss.backward()\n",
        "\n",
        "        noise = torch.randn((batch_size, dim_vector_ruido)).to(device)\n",
        "        fake_images = g(noise)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "        fake_output = d(fake_images.detach())\n",
        "        fake_loss = criterio(fake_output, fake_labels)\n",
        "        fake_loss.backward()\n",
        "\n",
        "        discriminator_loss = real_loss + fake_loss\n",
        "        d_optimizer.step()\n",
        "\n",
        "        g.train()\n",
        "        d.eval()\n",
        "\n",
        "        g_optimizer.zero_grad()  # Cambiado de g_optimisador a g_optimizer\n",
        "        generated_images = g(noise)\n",
        "        generator_loss = criterio(d(generated_images), real_labels)\n",
        "        generator_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f'Epoch [{epoch}/{num_epochs}], Step [{i}/{len(data_loader)}], '\n",
        "                  f'Discriminator Loss: {discriminator_loss.item():.4f}, '\n",
        "                  f'Generator Loss: {generator_loss.item():.4f}')\n",
        "\n",
        "    # Imprimir estadísticas y visualizar imágenes generadas al final de cada época\n",
        "    with torch.no_grad():\n",
        "        g.eval()\n",
        "        noise = torch.randn(16, dim_vector_ruido).to(device)\n",
        "        generated_images = g(noise).detach().cpu()\n",
        "\n",
        "        # Convertir las imágenes al rango [0, 1]\n",
        "        generated_images = (generated_images + 1) / 2.0\n",
        "\n",
        "        # Visualizar las imágenes generadas\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"Generated Images - Epoch {epoch + 1}\")\n",
        "        plt.imshow(vutils.make_grid(generated_images, nrow=4).permute(1, 2, 0).numpy())\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "xOaEJmpkzNvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(g.state_dict(), 'modelo_gatos.pt')"
      ],
      "metadata": {
        "id": "nUbOcTLlt8m2"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suponiendo que \"Generador\" es la clase de tu generador y \"ruta_modelo\" es la ruta del modelo guardado\n",
        "generador = Generador(80, 60*60*3)  # Ajusta input_size y output_size según tu implementación\n",
        "generador.load_state_dict(torch.load(\"/content/modelo_gatos.pt\"))\n",
        "generador.to(device)\n",
        "generador.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    generador.eval()\n",
        "    noise = torch.randn(1, dim_vector_ruido).to(device)\n",
        "    generated_image = generador(noise).detach().cpu()\n",
        "\n",
        "# Convertir la imagen al rango [0, 1]\n",
        "generated_image = (generated_image + 1) / 2.0\n",
        "\n",
        "generated_image_np = generated_image.squeeze().permute(1, 2, 0).numpy()\n",
        "\n",
        "# Visualizar la imagen generada\n",
        "plt.imshow(generated_image_np)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "k3ANH_wEuUBR",
        "outputId": "8ed10be9-7a1b-406a-8660-2a0c543f271a"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-6965625dc0cc>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgenerated_image\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgenerated_image_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Visualizar la imagen generada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 1 is not equal to len(dims) = 3"
          ]
        }
      ]
    }
  ]
}